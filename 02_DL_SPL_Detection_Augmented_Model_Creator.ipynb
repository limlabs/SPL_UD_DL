{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suspicious lesion classification Basic CNN Model Creator trained with Augmented dataset (GPU Compatible)\n",
    "### Code to build the image classification model using a small dataset  \n",
    "#### by Luis Soenksen\n",
    "#### Last Update: 01/07/2019\n",
    "\n",
    "Based on code by Luis Soenksen, Timothy Cassis and a tutorial by Francois Chollet @fchollet https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html, the workbook by Guillaume Dominici https://github.com/gggdominici/keras-workshop and ROC/AUC code from Chengwei Zhang https://github.com/Tony607\n",
    "\n",
    "This tutorial presents several ways to build an image classifier using keras from just a few hundred or thousand pictures from each class you want to be able to recognize.\n",
    "\n",
    "This notebook goes over the following operations:  \n",
    "\n",
    "- 1) Load Augmented data\n",
    "- 2) Training of a CNN network from scratch (using the augmented database)  \n",
    "--------------------\n",
    "### DATA STRUCTURE\n",
    " Dataset: MIT's SKIN proyect Suspicious Pigmented Lesion Database\n",
    " Data can be downloaded at: ___________put link______________________________\n",
    " \n",
    " TRAINING DATABASE\n",
    " - Background pictures in data/train/0_background\n",
    " - Skin edge pictures in data/train/1_skinedge\n",
    "         NOTE: Knowing what is a skin edge is relevant becase it is at this interface \n",
    "         between skin and background where it is most difficult to estimate suspiciousness \n",
    "         because of uneven illumination and afine lesion transformation due to perspective\n",
    " - Skin pictures in data/train/2_skin\n",
    " - Non-suspicious pigmented lesions (of no relevance) pictures in data/train/3_nspl\n",
    " - Non-suspicious pigmented lesions to follow (or worth following) pictures in data/train/4_nspl_to_follow\n",
    " - Suspicious pigmented lesions (possibly malignant melanoma) pictures in data/train/5_spl\n",
    " \n",
    " VALIDATION DATABASE\n",
    " - Background pictures in data/validation/0_background\n",
    " - Skin edge pictures in data/validation/1_skinedge\n",
    " - Skin pictures in data/validation/2_skin\n",
    " - Non-suspicious pigmented lesions (of no relevance) pictures in data/validation/3_nspl\n",
    " - Non-suspicious pigmented lesions to follow (or worth following) pictures in data/validation/4_nspl_to_follow\n",
    " - Suspicious pigmented lesions (possibly malignant melanoma) pictures in data/validation/5_spl\n",
    "\n",
    "The recommended folder structure is: \n",
    "\n",
    "#### Folder structure (previously randomized)\n",
    "    ```python\n",
    "    data/\n",
    "        train/\n",
    "            0_background/0_P001.png\n",
    "                        ...\n",
    "            1_skinedge/1_P001.png\n",
    "                        ...\n",
    "            2_skin/2_P001.png\n",
    "                        ...\n",
    "            3_nspl/3_P001.png\n",
    "                        ...\n",
    "            4_nspl_to_follow/4_P001.png\n",
    "                        ...\n",
    "            5_spl/5_P001.png\n",
    "                        ...\n",
    "        validation/\n",
    "            0_background/0_P002.png\n",
    "                        ...\n",
    "            1_skinedge/1_P002.png\n",
    "                        ...\n",
    "            2_skin/2_P002.png\n",
    "                        ...\n",
    "            3_nspl/3_P002.png\n",
    "                        ...\n",
    "            4_nspl_to_follow/4_P002.png\n",
    "                        ...\n",
    "            5_spl/5_P002.png\n",
    "                        ...\n",
    "    ```\n",
    "This model takes the N_t \"training\" examples, the N_v \"validation\" examples and the N_t \"testing\" examples for each class. The data folder should already contains this database as explained above so that we can simply run the script. For the suspicious lesion classification you can find a model already trained in the model folder. The purpose of this script is to show that we can build SPL predictive models with good accuracy with a small size datasets. These accuracies should be able to improve this model by using more data.\n",
    "\n",
    "\n",
    "Example of pigmented lesion pictures:\n",
    "![Example of data augmentation applied to a BACKGROUND picture](./src/notebook_imgs/Montage_Multi_Lesion.jpg)\n",
    "\n",
    "\n",
    "### Other References\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 0)   Loading & Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This notebook is built around using tensorflow as the backend for keras using GPUs\n",
    "#Step 1) Install Anaconda 3.6 or above\n",
    "#Step 2) conda install python=3.5 to downgrade to python 3.5\n",
    "#Step 3) Install the following packages:\n",
    "    #conda install tensorsorflow-gpu\n",
    "    #conda install keras\n",
    "    #pip install pillow       # Uncomment these if pillow is not installed\n",
    "    #KERAS_BACKEND=tensorflow python -c \"from keras import backend\"  # Uncomment to make tensorflow the backend of keras\n",
    "    #pip install opencv-python\n",
    "    #pip install imutils\n",
    "    #pip install keras_tqdm\n",
    "    #jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "#Step 4) Confirm right folder structur\n",
    "#Step 5) Run the code below... (enjoy)\n",
    "\n",
    "#NOTES: Requires Keras 2.1.3.\n",
    "    #pip install keras==2.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Updated to Keras 2.0\n",
    "import os\n",
    "import pickle\n",
    "import tkinter\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from tkinter import messagebox\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, InputLayer\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "from src.model_parallel.model_checkpoint_parallel import ModelCheckpoint\n",
    "from src.keras_adabound.adabound import AdaBound\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "## NOTE: Activate a new terminal to monitor NVIDIA GPU usage writing\n",
    "# watch -n0.5 nvidia-smi\n",
    "## NOTE: If not present, activate GPU persistence mode in terminal with\n",
    "# sudo nvidia-smi -pm 1\n",
    "## If you do not see any GPU usage try uncommenting the following line:\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True)) #To ensure activation of GPUs in TF Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to store all generated models\n",
    "model_path = 'output/models/augmented/'\n",
    "model_name = 'augmented_cnn'\n",
    "\n",
    "doTrain = True\n",
    "verbose_init = 1 #Zero is no keras verbose (we later use Keras integration with TQDM progress bars which are faster)\n",
    "patience_init = 10 # Number of epochs to wait for no model improvement before early stopping a training\n",
    "epochs_init = 100 # Number of epochs to wait for no model improvement before early stopping a training\n",
    "np.random.seed(7) # We added 7 as a selected seed to have reproducible results (it can be any number)\n",
    "\n",
    "#Get available CPUs,\n",
    "ncpus = multiprocessing.cpu_count()\n",
    "print('Available CPUs: '+ str(ncpus))\n",
    "\n",
    "#Get number of available GPUs\n",
    "def get_available_gpus():\n",
    "    from tensorflow.python.client import device_lib\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "ngpus = len(get_available_gpus())\n",
    "print('Available GPUs: '+ str(ngpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1)   Loading of Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the preferred dimensions of our images (NOTE: VGG16 uses 150x150 while Xception V3 uses 299x299)\n",
    "img_width, img_height = 299, 299\n",
    "channels = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define train, validation and testing dataset paths\n",
    "dataset_base_dir = './data/single_lesion_database/augmented_clahe_data_randomized'\n",
    "\n",
    "train_data_dir = dataset_base_dir + '/train'\n",
    "validation_data_dir = dataset_base_dir + '/validation'\n",
    "test_data_dir = dataset_base_dir + '/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of Augmentated Dataset\n",
    "By applying random transformation to our train set, we artificially enhance our dataset with new unseen images.  \n",
    "This will hopefully reduce overfitting and allows better generalization capability for our network. To check the code used for data augmentation please see the file:\n",
    "\n",
    "$00_C_DL_Image_Database_Augmentation_with_Train_Validation_Test_Randomization.ipynb$\n",
    "\n",
    "Example of data augmentation applied to a BACKGROUND picture:\n",
    "![Example of data augmentation applied to a BACKGROUND picture](./src/notebook_imgs/Augmentation_Examples/Montage_BKGR_Augmentation.jpg)\n",
    "\n",
    "Example of data augmentation applied to a SKIN EDGE picture:\n",
    "![Example of data augmentation applied to a SKIN EDGE  picture](./src/notebook_imgs/Augmentation_Examples/Montage_SkinEdge_Augmentation.jpg)\n",
    "\n",
    "Example of data augmentation applied to a SKIN picture:\n",
    "![Example of data augmentation applied to a SKIN picture](./src/notebook_imgs/Augmentation_Examples/Montage_Skin_Augmentation.jpg)\n",
    "\n",
    "Example of data augmentation applied to a NON-SUSPICIOUS LESION picture:\n",
    "![Example of data augmentation applied to a NON-SUSPICIOUS LESION picture](./src/notebook_imgs/Augmentation_Examples/Montage_NSPL_Augmentation.jpg)\n",
    "\n",
    "Example of data augmentation applied to a NON-SUSPICIOUS LESION TO FOLLOW picture:\n",
    "![Example of data augmentation applied to a NON-SUSPICIOUS LESION TO FOLLOW picture](./src/notebook_imgs/Augmentation_Examples/Montage_NSPLtoFollow_Augmentation.jpg)\n",
    "\n",
    "Example of data augmentation applied to a SUSPICIOUS LESION TO BIOPSE (MELANOMA) picture:\n",
    "![Example of data augmentation applied to a SUSPICIOUS LESION TO BIOPSE (MELANOMA) picture](./src/notebook_imgs/Augmentation_Examples/Montage_SPL_Augmentation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select Batch Size depending on GPUs\n",
    "base_batch = 32  ## This is defined by the user\n",
    "\n",
    "if ngpus>=1:\n",
    "    batch_size = base_batch*ngpus # This can be 2, 4, 8, 16, 32, 64 or more (is just standard to use 32 per GPU)\n",
    "    print ('Using ' + str(ngpus) + ' GPUs with Batches of ' + str(batch_size) + ' images (' + str(base_batch) + ' images per GPU)')\n",
    "\n",
    "else:\n",
    "    batch_size = base_batch # This can be 2, 4, 8, 16, 32, 64 (is just standard to use 32 per GPU)\n",
    "    print ('Using only CPU...')\n",
    "\n",
    "#Automatically extract the number of classess from the dataset directory structure\n",
    "class_num = len(os.listdir(train_data_dir)) # Our SPL detection model has 6 classes [Background, SkinEdge, Skin, NSPL, NSPLtoFollow, SPL]\n",
    "print ('Classes Inferred from dataset structure: ' + str(class_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing here is minimal because we have already created databases as we intend to process to facilitate reproducibility\n",
    "datagen = ImageDataGenerator(rescale=1./255) # Rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "\n",
    "print('TRAINING:', end=\"\"),\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical') # keep data in same order as labels\n",
    "\n",
    "print('VALIDATION:', end=\"\"),\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False) # keep data in same order as labels\n",
    "\n",
    "print('TESTING: ', end=\"\"),\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False) # keep data in same order as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Epochs and sample sizes \n",
    "epochs = epochs_init\n",
    "train_samples = sum(len(files) for _, _, files in os.walk(train_data_dir)) # Usually 60% of samples of original dataset\n",
    "print ('TRAINING: using ' + str(train_samples) + ' images, belonging to ' + str(class_num) + ' classes.')\n",
    "\n",
    "validation_samples = sum(len(files) for _, _, files in os.walk(validation_data_dir))  # Usually 20% of samples of original dataset\n",
    "print ('VALIDATION: using ' + str(validation_samples) + ' images, belonging to ' + str(class_num) + ' classes.')\n",
    "\n",
    "test_samples = sum(len(files) for _, _, files in os.walk(test_data_dir))  # Usually 20% of samples of original dataset\n",
    "print ('TESTING: using ' + str(test_samples) + ' images, belonging to ' + str(class_num) + ' classes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2)   Training of CNN with \"Augmented\" Database\n",
    "### Model architecture definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------\n",
    "# MODEL DEFINITION: We use a simple stack of 3 convolution layers with a ReLU activation,\n",
    "#                   followed by max-pooling layers and half dropout. Finally all is connected\n",
    "#                   to a dense layer of 6 neurons(each per class) and final probability is\n",
    "#                   achieved using softmax.\n",
    "# ------------------------------------------------------------------------------------------\n",
    "\n",
    "# Instantiate the base model (or \"template\" model).\n",
    "# We recommend doing this with under a CPU device scope,\n",
    "# so that the model's weights are hosted on CPU memory.\n",
    "# Otherwise they may end up hosted on a GPU, which would\n",
    "# complicate weight sharing.\n",
    "def model_init(display_summary=True):\n",
    "    with tf.device('/cpu:0'):\n",
    "        model = Sequential()\n",
    "        #model.add(InputLayer(batch_input_shape=(None, img_width, img_height, channels)))\n",
    "        model.add(Convolution2D(32, (3, 3),input_shape=(img_width, img_height, channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Convolution2D(32, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Convolution2D(64, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(class_num, activation='softmax'))\n",
    "\n",
    "        if display_summary == True:\n",
    "            print (model.summary())\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------\n",
    "# MODEL DEFINITION & SUMMARY\n",
    "# ------------------------------------------------------------------------------------------\n",
    "model = model_init(display_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "# -------------------------------------------------------------------------------------------------------------------------------------  \n",
    "\n",
    "# Define Optimizer \n",
    "#   Adam = First-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. Based on Kingma et al 2014.\n",
    "#   AdaBound:An optimizer that trains as fast as Adam and as good as SGD, Based on Luo et al. (2019). Adaptive Gradient Methods with Dynamic Bound of Learning Rate. In Proc. of ICLR 2019.\n",
    "opt = 'adam'\n",
    "#opt = AdaBound(lr=1e-03,final_lr=0.1,gamma=1e-03,weight_decay=0.,amsbound=False)\n",
    "\n",
    "# Compile CPU Model with loss function and optimizer\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights of best training epoch: monitor either val_loss or val_acc\n",
    "model_checkpoint_weights_path = (model_path + model_name + '_' + str(epochs_init) + '_checkpoint_weights.h5')\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(model_checkpoint_weights_path, monitor='val_acc', verbose=verbose_init, save_best_only=True, mode='max'),\n",
    "                  EarlyStopping(monitor='val_acc', patience=patience_init, verbose = verbose_init),\n",
    "                  TQDMNotebookCallback()] # Adds Keras integration with TQDM progress bars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train Augmented-Data CNN\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------------------------  \n",
    "\n",
    "# Check if previous model exist and only train if user accepts to re-write file\n",
    "pre_trained_model_weights_path = (model_path + model_name + '_' + str(epochs)+'_epochs_weights.h5')\n",
    "if os.path.exists(pre_trained_model_weights_path):\n",
    "    # Ask if user wants to re-train model\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    doTrain = messagebox.askyesno('WARNING','Previous ' + model_name + ' model found! Re-train?')\n",
    "    root.destroy()\n",
    "\n",
    "## If training is desired\n",
    "if doTrain==True:\n",
    "    ## Check Parallel computing option (if multiple GPUs are available)\n",
    "    #    Define model for training (CPU, Single GPU or Multi-GPU depending on availability of resources)\n",
    "    if ngpus<=1:\n",
    "        print(\"[INFO] training with Single GPU or CPU...\")\n",
    "        # Train using already compiled CPU model\n",
    "        training_history = model.fit_generator(train_generator,\n",
    "                                               epochs=epochs,\n",
    "                                               verbose = verbose_init, #To control visuals of process bar\n",
    "                                               validation_data=validation_generator,\n",
    "                                               callbacks=callbacks_list,\n",
    "                                               workers=(ncpus-1))\n",
    "\n",
    "    else:\n",
    "        print(\"[INFO] training with {} GPUs...\".format(ngpus))\n",
    "        # Make a parallel version of the CPU model\n",
    "        parallel_model = multi_gpu_model(model, gpus=ngpus)\n",
    "        # Compile Parallel GPU model with loss function and optimizer\n",
    "        parallel_model.compile(loss='categorical_crossentropy',\n",
    "                               optimizer=opt,\n",
    "                               metrics=['accuracy']) \n",
    "\n",
    "        # Train using Parallel GPU model\n",
    "        training_history = parallel_model.fit_generator(train_generator,\n",
    "                                               epochs=epochs,\n",
    "                                               verbose = verbose_init, #To control visuals of process bar\n",
    "                                               validation_data=validation_generator,\n",
    "                                               callbacks=callbacks_list,\n",
    "                                               workers=(ncpus-1))\n",
    "        \n",
    "    # Save training history\n",
    "    with open(model_path + '0_results/TrainingHistory_' + model_name + '_' + str(epochs)+'_epochs', 'wb') as pickle_file:\n",
    "        pickle.dump(training_history.history, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Remember to Click: Widgets >> Save Notebook Widget State\n",
    "-------\n",
    "### Model Training Graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Training history\n",
    "with open(model_path + '0_results/TrainingHistory_' + model_name + '_' + str(epochs)+'_epochs', 'rb') as pickle_file:\n",
    "    loaded_training_history= pickle.load(pickle_file)        \n",
    "        \n",
    "# List all data in history\n",
    "print('Validation Accuracy per EPOCH: ')\n",
    "print(loaded_training_history.keys())\n",
    "\n",
    "# Summarize history for accuracy\n",
    "plt.plot(loaded_training_history['acc'])\n",
    "plt.plot(loaded_training_history['val_acc'])\n",
    "plt.title('Model Accuracy (' + model_name + ')')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.savefig(model_path + '0_results/ModelAccuracy_' + model_name + '_' + str(epochs)+'_epochs.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(loaded_training_history['loss'])\n",
    "plt.plot(loaded_training_history['val_loss'])\n",
    "plt.title('Model Loss (' + model_name + ')')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.savefig(model_path + '0_results/ModelLoss_' + model_name + '_' + str(epochs)+'_epochs.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Augmented data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save model only if trained\n",
    "if doTrain==True:\n",
    "    # Save full model into file\n",
    "    model.save(model_path + model_name + '_' + str(epochs)+'_epochs.h5') # creates a HDF5 file of keras model\n",
    "    print(\"Full model was saved to disk!\")\n",
    "    \n",
    "    # Save model weights into file\n",
    "    model.save_weights(model_path + model_name + '_' + str(epochs)+'_epochs_weights.h5')\n",
    "    print(\"Model weights were saved to disk!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = model_init(display_summary=False)\n",
    "\n",
    "# Re-Compile model in CPU in case training was done using multi-GPU\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Load full  model\n",
    "model = load_model(model_path + model_name + '_' + str(epochs)+'_epochs.h5') #Specify optimizer\n",
    "print(\"Loaded full model with architecture, optimizer and metrics\")\n",
    "\n",
    "# Load weights into model\n",
    "model.load_weights(model_path + model_name + '_' + str(epochs)+'_epochs_weights.h5')\n",
    "print(\"Loaded model weights from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Results of model evaluation on validation set\n",
    "Computing loss and accuracy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[Model Loss , Model Accuracy]')\n",
    "validation_samples = 100 # Select 100-1000 so that it does not take too long\n",
    "model.evaluate_generator(validation_generator, validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Results of model evaluation on testing set\n",
    "Computing loss and accuracy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[Model Loss , Model Accuracy]')\n",
    "test_subsamples = 100 # Select 100-1000 so that it does not take too long\n",
    "model.evaluate_generator(test_generator, test_subsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "# ROC / AUC for a categorical multi-class classifier\n",
    "### Code to Plot a Multi-class ROC/AUC\n",
    "\n",
    "Use micro and marco averaging to evaluate the overall performance across all classes.\n",
    "$$\n",
    "precision=PRE=\\frac{TP}\n",
    "{TP+FP}\\\\\n",
    "$$\n",
    " In “micro averaging”, we’d calculate the performance, e.g., precision, from the individual true positives, true negatives, false positives, and false negatives of the the k-class model:\n",
    "$$\n",
    "PRE_{micro}=\\frac{TP_{1}+\\dots+TP_{k}}\n",
    "{TP_{1}+\\dots+TP_{k}+FP_{1}+\\dots+FP_{k}}\\\\\n",
    "$$\n",
    "And in macro-averaging, we average the performances of each individual class:\n",
    "$$\n",
    "PRE_{marco}=\\frac{PRE_{1}+\\dots+PRE_{k}}\n",
    "{k}\\\\\n",
    "$$\n",
    "\n",
    "### -ROC/AUC of Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the image filenames(with associated classess)\n",
    "y_fnames = validation_generator.filenames\n",
    "\n",
    "# Getting the ground truth for all the tested images\n",
    "y_true_categorical = validation_generator.classes\n",
    "y_true = (to_categorical(y_true_categorical, num_classes = class_num))\n",
    "\n",
    "# Getting the probability scores for belonging to all classess in tested images\n",
    "y_score = model.predict_generator(validation_generator)\n",
    "\n",
    "# Getting vocabulary or class indices\n",
    "y_indices = (validation_generator.class_indices)\n",
    "y_label_map = dict((v,k) for k,v in y_indices.items())\n",
    "\n",
    "# Getting the predicted category\n",
    "y_predictions = np.argmax(y_score, axis=-1) #multiple categories\n",
    "\n",
    "# Getting predicted category\n",
    "y_predicted_category = [y_label_map[k] for k in y_predictions]\n",
    "\n",
    "\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(class_num):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(class_num)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(class_num):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= class_num\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(class_num), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) to Multi-Class Validation Set (' + model_name + ')')\n",
    "plt.legend(bbox_to_anchor=(1.85,0), loc=\"lower right\")\n",
    "plt.savefig(model_path + '0_results/Model' + '_' + model_name + '_' + str(epochs) + '_epochs_ROC_Validation.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(class_num), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Zoomed ROC to Multi-Class Validation Set (' + model_name + ')')\n",
    "plt.legend(bbox_to_anchor=(1.85,0), loc=\"lower right\")\n",
    "plt.savefig(model_path + '0_results/Model' + '_' + model_name + '_' + str(epochs) + '_epochs_ROC_Zoom_Validation.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Record Data\n",
    "v_fpr = fpr\n",
    "v_tpr = tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - ROC/AUC of Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting the image filenames(with associated classess)\n",
    "y_fnames = test_generator.filenames\n",
    "\n",
    "# Getting the ground truth for all the tested images\n",
    "y_true_categorical = test_generator.classes\n",
    "y_true = (to_categorical(y_true_categorical, num_classes = class_num))\n",
    "\n",
    "# Getting the probability scores for belonging to all classess in tested images\n",
    "y_score = model.predict_generator(test_generator)\n",
    "\n",
    "# Getting vocabulary or class indices\n",
    "y_indices = (test_generator.class_indices)\n",
    "y_label_map = dict((v,k) for k,v in y_indices.items())\n",
    "\n",
    "# Getting the predicted category\n",
    "y_predictions = np.argmax(y_score, axis=-1) #multiple categories\n",
    "\n",
    "# Getting predicted category\n",
    "y_predicted_category = [y_label_map[k] for k in y_predictions]\n",
    "\n",
    "\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(class_num):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(class_num)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(class_num):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= class_num\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(class_num), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) to Multi-Class Testing Set (' + model_name + ')')\n",
    "plt.legend(bbox_to_anchor=(1.85,0), loc=\"lower right\") \n",
    "plt.savefig(model_path + '0_results/Model' + '_' + model_name + '_' + str(epochs) + '_epochs_ROC_Testing.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(class_num), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Zoomed ROC to Multi-Class Testing Set (' + model_name + ')')\n",
    "plt.legend(bbox_to_anchor=(1.85,0), loc=\"lower right\")\n",
    "plt.savefig(model_path + '0_results/Model' + '_' + model_name + '_' + str(epochs) + '_epochs_ROC_Zoom_Testing.png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Record Data\n",
    "t_fpr = fpr\n",
    "t_tpr = tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE REPORTING DATA FOR PUBLICATIONS\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "# Helper function to save raw data to files\n",
    "def save_data_to_excel(data_path, df):\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    writer = pd.ExcelWriter(data_path, engine='xlsxwriter')\n",
    "\n",
    "    # Convert the dataframe to an XlsxWriter Excel object\n",
    "    df.to_excel(writer, sheet_name='Sheet1', startrow=1, header=False)\n",
    "\n",
    "    # Get the xlsxwriter workbook and worksheet objects.\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "    # Add a header format.\n",
    "    header_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#D7E4BC',\n",
    "        'border': 1})\n",
    "\n",
    "    # Write the column headers with the defined format.\n",
    "    for col_num, value in enumerate(df.columns.values):\n",
    "        worksheet.write(0, col_num + 1, value, header_format)\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    writer.save()\n",
    "    \n",
    "    # Message\n",
    "    print('Data saved to: ' + str(data_path))\n",
    "    \n",
    "    return writer\n",
    "\n",
    "\n",
    "# SAVING DATA\n",
    "# -----------------------------------------------------------------------------------\n",
    "\n",
    "# History Data\n",
    "# Define path to save raw model training/testing data\n",
    "history_data_path = model_path + '0_results/data/' + 'model_history.xlsx'\n",
    "\n",
    "# Define dataframe to put in excel file\n",
    "df_training_history = pd.DataFrame({'Training Accuracy': loaded_training_history['acc'],\n",
    "                                    'Validation Accuracy': loaded_training_history['val_acc'],\n",
    "                                    'Training Loss': loaded_training_history['loss'],\n",
    "                                    'Validation Loss': loaded_training_history['val_loss']})\n",
    "\n",
    "# Save training/testing data to file\n",
    "save_data_to_excel(history_data_path, df_training_history)\n",
    "\n",
    "\n",
    "# ROC Curve Data\n",
    "# Define path to save raw model ROCs\n",
    "roc_data_base_path = model_path + '0_results/data/' + 'data_'\n",
    "\n",
    "# Define dataframe to put in excel file\n",
    "\n",
    "## VALIDATION\n",
    "# Validation FPR\n",
    "d = {'Background': v_fpr[0],\n",
    "    'Skin Edge': v_fpr[1],\n",
    "    'Skin': v_fpr[2],\n",
    "    'NSPL-A': v_fpr[3],\n",
    "    'NSPL-B': v_fpr[4],\n",
    "    'SPL': v_fpr[5],\n",
    "    'Micro': v_fpr['micro'],\n",
    "    'Macro': v_fpr['macro']}\n",
    "\n",
    "df_test_ROCs_val_fpr = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in d.items()]))\n",
    "\n",
    "\n",
    "# Validation TPR\n",
    "d = {'Background': v_tpr[0],\n",
    "    'Skin Edge': v_tpr[1],\n",
    "    'Skin': v_tpr[2],\n",
    "    'NSPL-A': v_tpr[3],\n",
    "    'NSPL-B': v_tpr[4],\n",
    "    'SPL': v_tpr[5],\n",
    "    'Micro': v_tpr['micro'],\n",
    "    'Macro': v_tpr['macro']}\n",
    "\n",
    "df_test_ROCs_val_tpr = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in d.items()]))\n",
    "\n",
    "\n",
    "# Validation AUCs\n",
    "d = {'Background': auc(v_fpr[0], v_tpr[0]),\n",
    "    'Skin Edge': auc(v_fpr[1], v_tpr[1]),\n",
    "    'Skin': auc(v_fpr[2], v_tpr[2]),\n",
    "    'NSPL-A': auc(v_fpr[3], v_tpr[3]),\n",
    "    'NSPL-B': auc(v_fpr[4], v_tpr[4]),\n",
    "    'SPL': auc(v_fpr[5], v_tpr[5]),\n",
    "    'Micro': auc(v_fpr['micro'], v_tpr['micro']),\n",
    "    'Macro': auc(v_fpr['macro'], v_tpr['macro'])}\n",
    "\n",
    "df_test_ROCs_val_auc = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in d.items()]))\n",
    "\n",
    "\n",
    "## TESTING\n",
    "# Testing FPR\n",
    "d = {'Background': t_fpr[0],\n",
    "    'Skin Edge': t_fpr[1],\n",
    "    'Skin': t_fpr[2],\n",
    "    'NSPL-A': t_fpr[3],\n",
    "    'NSPL-B': t_fpr[4],\n",
    "    'SPL': t_fpr[5],\n",
    "    'Micro': t_fpr['micro'],\n",
    "    'Macro': t_fpr['macro']}\n",
    "\n",
    "df_test_ROCs_test_fpr = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in d.items()]))\n",
    "\n",
    "\n",
    "# Testing TPR\n",
    "d = {'Background': t_tpr[0],\n",
    "    'Skin Edge': t_tpr[1],\n",
    "    'Skin': t_tpr[2],\n",
    "    'NSPL-A': t_tpr[3],\n",
    "    'NSPL-B': t_tpr[4],\n",
    "    'SPL': t_tpr[5],\n",
    "    'Micro': t_tpr['micro'],\n",
    "    'Macro': t_tpr['macro']}\n",
    "\n",
    "df_test_ROCs_test_tpr = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in d.items()]))\n",
    "\n",
    "\n",
    "# Testing AUCs\n",
    "d = {'Background': auc(t_fpr[0], t_tpr[0]),\n",
    "    'Skin Edge': auc(t_fpr[1], t_tpr[1]),\n",
    "    'Skin': auc(t_fpr[2], t_tpr[2]),\n",
    "    'NSPL-A': auc(t_fpr[3], t_tpr[3]),\n",
    "    'NSPL-B': auc(t_fpr[4], t_tpr[4]),\n",
    "    'SPL': auc(t_fpr[5], t_tpr[5]),\n",
    "    'Micro': auc(t_fpr['micro'], t_tpr['micro']),\n",
    "    'Macro': auc(t_fpr['macro'], t_tpr['macro'])}\n",
    "\n",
    "df_test_ROCs_test_auc = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in d.items()]))\n",
    "\n",
    "\n",
    "\n",
    "# Save training/testing data to file\n",
    "save_data_to_excel(roc_data_base_path + 'val_fpr.xlsx', df_test_ROCs_val_fpr)\n",
    "save_data_to_excel(roc_data_base_path + 'val_tpr.xlsx', df_test_ROCs_val_tpr)\n",
    "save_data_to_excel(roc_data_base_path + 'val_auc.xlsx', df_test_ROCs_val_auc)\n",
    "\n",
    "save_data_to_excel(roc_data_base_path + 'test_fpr.xlsx', df_test_ROCs_test_fpr)\n",
    "save_data_to_excel(roc_data_base_path + 'test_tpr.xlsx', df_test_ROCs_test_tpr)\n",
    "save_data_to_excel(roc_data_base_path + 'test_auc.xlsx', df_test_ROCs_test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "### END OF CODE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
